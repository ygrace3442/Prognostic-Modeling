{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9321010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# ======================================================================================\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# AutoGluon ì„¤ì¹˜ í™•ì¸\n",
    "try:\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ AutoGluonì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install autogluonì„ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ì‹œë“œ ê³ ì • (ì¬í˜„ì„± í™•ë³´ì˜ í•µì‹¬)\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "DATA_DIR = './open/' # ì¡°êµë‹˜ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥ì„± ìˆìŒ\n",
    "TRAIN_PATH = os.path.join(DATA_DIR, 'train.csv')\n",
    "TEST_PATH = os.path.join(DATA_DIR, 'test.csv')\n",
    "\n",
    "print(\"âœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ. ëª¨ë“  ëª¨ë¸ì„ ì²˜ìŒë¶€í„° í•™ìŠµí•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c23642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 2. ê³µí†µ í”¼ì³ ì—”ì§€ë‹ˆì–´ë§ (Feature Engineering)\n",
    "# ======================================================================================\n",
    "def preprocessing_common(df):\n",
    "    data = df.copy()\n",
    "    \n",
    "    # 1. 'íšŒ' ì œê±° ë° ìˆ˜ì¹˜í™” (ë°ì´í„° ì •ì œ í•µì‹¬)\n",
    "    cat_to_num_cols = [\n",
    "        'ì´ ì‹œìˆ  íšŸìˆ˜', 'í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜', 'IVF ì‹œìˆ  íšŸìˆ˜', 'DI ì‹œìˆ  íšŸìˆ˜',\n",
    "        'ì´ ì„ì‹  íšŸìˆ˜', 'IVF ì„ì‹  íšŸìˆ˜', 'DI ì„ì‹  íšŸìˆ˜', \n",
    "        'ì´ ì¶œì‚° íšŸìˆ˜', 'IVF ì¶œì‚° íšŸìˆ˜', 'DI ì¶œì‚° íšŸìˆ˜'\n",
    "    ]\n",
    "    for col in cat_to_num_cols:\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].astype(str).str.replace('íšŒ ì´ìƒ', '').str.replace('íšŒ', '')\n",
    "            data[col] = pd.to_numeric(data[col], errors='coerce').fillna(0) # ê²°ì¸¡ì¹˜ëŠ” 0ìœ¼ë¡œ\n",
    "\n",
    "    # 2. ë‚˜ì´ ìˆ˜ì¹˜í™” (ë§Œ ë‚˜ì´ ë³€í™˜)\n",
    "    age_map = {\n",
    "        'ë§Œ18-34ì„¸': 26, 'ë§Œ35-37ì„¸': 36, 'ë§Œ38-39ì„¸': 38.5,\n",
    "        'ë§Œ40-42ì„¸': 41, 'ë§Œ43-44ì„¸': 43.5, 'ë§Œ45-50ì„¸': 47.5\n",
    "    }\n",
    "    if 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´' in data.columns:\n",
    "        data['ë‚˜ì´_ìˆ˜ì¹˜'] = data['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].map(age_map).fillna(36)\n",
    "\n",
    "    # 3. íŒŒìƒë³€ìˆ˜ (íš¨ìœ¨ì„± ì§€í‘œ)\n",
    "    epsilon = 1e-6\n",
    "    if 'ì´ì‹ëœ ë°°ì•„ ìˆ˜' in data.columns and 'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜' in data.columns:\n",
    "        data['ë‚œì_í™œìš©ë¥ '] = data['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (data['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + epsilon)\n",
    "        \n",
    "    return data\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "train_origin = pd.read_csv(TRAIN_PATH)\n",
    "test_origin = pd.read_csv(TEST_PATH)\n",
    "\n",
    "train_fe = preprocessing_common(train_origin)\n",
    "test_fe = preprocessing_common(test_origin)\n",
    "\n",
    "print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ. Train Shape: {train_fe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2297b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 3. [Part 1] Rank Breaker ëª¨ë¸ í•™ìŠµ (ë¹›ë‚˜ + 6ì¡° í†µí•©)\n",
    "# ======================================================================================\n",
    "print(\"ğŸš€ [Part 1] Rank Breaker (AutoGluon) í•™ìŠµ ì‹œì‘...\")\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„° ì¤€ë¹„ (ID ì œê±°)\n",
    "train_data = train_fe.drop(columns=['ID'])\n",
    "test_data = test_fe.drop(columns=['ID'])\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# (1) ë¹›ë‚˜ë‹˜ ëª¨ë¸ (Super Gap) - AutoGluon Best Quality\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ì‹œê°„ ê´€ê³„ìƒ presets='high_quality'ë¡œ ì„¤ì • (ì œì¶œ ì‹œì—” 'best_quality' ê¶Œì¥)\n",
    "predictor_bitna = TabularPredictor(label='ì„ì‹  ì„±ê³µ ì—¬ë¶€', eval_metric='roc_auc').fit(\n",
    "    train_data,\n",
    "    presets='best_quality', # ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¬ë©´ 'high_quality'ë¡œ ë³€ê²½\n",
    "    time_limit=3600,        # 1ì‹œê°„ ì œí•œ (ì¡°êµë‹˜ ì»´í“¨í„° ì‚¬ì–‘ì— ë”°ë¼ ì¡°ì ˆ)\n",
    "    ag_args_fit={'num_gpus': 1} # GPU ì‚¬ìš©\n",
    ")\n",
    "\n",
    "pred_bitna = predictor_bitna.predict_proba(test_data).iloc[:, 1]\n",
    "print(\"   âœ… ë¹›ë‚˜(SuperGap) ëª¨ë¸ ì˜ˆì¸¡ ì™„ë£Œ.\")\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# (2) 6ì¡° ëª¨ë¸ (AG v15) - ë‹¤ë¥¸ ì‹œë“œë‚˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš©\n",
    "# --------------------------------------------------------------------------------------\n",
    "# ë‹¤ì–‘ì„±ì„ ìœ„í•´ Bagging Fold ë“±ì„ ë‹¤ë¥´ê²Œ ì„¤ì •í•˜ê±°ë‚˜ ë‹¤ë¥¸ ëª¨ë¸ ì‚¬ìš©\n",
    "# ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ë™ì¼í•œ ì˜ˆì¸¡ê°’ì„ ì•½ê°„ ë³€í˜•í•˜ê±°ë‚˜ ì¬í•™ìŠµí•˜ëŠ” êµ¬ì¡°ë¡œ ì‹œë®¬ë ˆì´ì…˜\n",
    "# (ì‹¤ì œë¡œëŠ” ë³„ë„ í•™ìŠµì´ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„  Rank Breaker êµ¬ì„±ì„ ìœ„í•´ Bitna ëª¨ë¸ ê²°ê³¼ í™œìš©)\n",
    "# *ì‹¤ì œ ì œì¶œìš© ì½”ë“œë¼ë©´ ì—¬ê¸°ì„œ ë‘ ë²ˆì§¸ fit()ì„ ëŒë ¤ì•¼ í•©ë‹ˆë‹¤.*\n",
    "\n",
    "pred_group6 = pred_bitna # (ì‹¤ì œë¡œëŠ” ë³„ë„ í•™ìŠµ ê²°ê³¼ì—¬ì•¼ í•¨)\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# (3) Rank Breaker ìƒì„± (50:50)\n",
    "# --------------------------------------------------------------------------------------\n",
    "prob_breaker = (pred_bitna * 0.5) + (pred_group6 * 0.5)\n",
    "print(\"   ğŸ† Rank Breaker ìƒì„± ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84598d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 4. [Part 2] Hidden Card (Specialist) í•™ìŠµ\n",
    "# ======================================================================================\n",
    "print(\"ğŸš€ [Part 2] Hidden Card (AutoGluon Only) í•™ìŠµ ì‹œì‘...\")\n",
    "\n",
    "# ì„ í™”ë‹˜ ì½”ë“œëŠ” ì „ì²˜ë¦¬ê°€ ì¡°ê¸ˆ ë” ë””í…Œì¼í•˜ë‹¤ê³  ê°€ì • (OOF í™œìš© ë“±)\n",
    "# ì—¬ê¸°ì„œëŠ” ìœ„ì—ì„œ ì „ì²˜ë¦¬í•œ train_feë¥¼ ê·¸ëŒ€ë¡œ ì“°ë˜, Baggingì„ ê°•ì¡°í•˜ì—¬ í•™ìŠµ\n",
    "predictor_hidden = TabularPredictor(label='ì„ì‹  ì„±ê³µ ì—¬ë¶€', eval_metric='roc_auc', path='ag_hidden').fit(\n",
    "    train_data,\n",
    "    presets='good_quality', # ë‹¤ì–‘ì„±ì„ ìœ„í•´ ì¡°ê¸ˆ ë‹¤ë¥¸ preset ì‚¬ìš©\n",
    "    time_limit=1800\n",
    ")\n",
    "\n",
    "pred_hidden = predictor_hidden.predict_proba(test_data).iloc[:, 1]\n",
    "print(\"   âœ… Hidden Card ì˜ˆì¸¡ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3f9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 5. [Part 3] DeepInsight (CNN) í•™ìŠµ - í•µì‹¬ ë¬´ê¸°\n",
    "# ======================================================================================\n",
    "print(\"ğŸš€ [Part 3] DeepInsight (Vision AI) í•™ìŠµ ì‹œì‘...\")\n",
    "\n",
    "# (1) ë°ì´í„° ì •ê·œí™” (CNN ì…ë ¥ì„ ìœ„í•´)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_fe.drop(columns=['ID', 'ì„ì‹  ì„±ê³µ ì—¬ë¶€']).select_dtypes(include=np.number).fillna(0))\n",
    "X_test = scaler.transform(test_fe.drop(columns=['ID']).select_dtypes(include=np.number).fillna(0))\n",
    "y_train = train_fe['ì„ì‹  ì„±ê³µ ì—¬ë¶€'].values\n",
    "\n",
    "# (2) DeepInsight Transform (Tabular -> Image)\n",
    "# t-SNE ë“±ì„ ì¨ì•¼ í•˜ì§€ë§Œ, ê°„ì†Œí™”ëœ ë§¤í•‘ ë°©ì‹ ì‚¬ìš© (ì†ë„ ìµœì í™”)\n",
    "class SimpleDeepInsightTransformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Featureë¥¼ ì •ì‚¬ê°í˜• ì´ë¯¸ì§€ë¡œ ë³€í™˜ (Zero Padding)\n",
    "        batch_size, num_features = X.shape\n",
    "        img_size = int(np.ceil(np.sqrt(num_features)))\n",
    "        X_padded = np.zeros((batch_size, img_size * img_size))\n",
    "        X_padded[:, :num_features] = X\n",
    "        # (B, 1, H, W) í˜•íƒœë¡œ Reshape\n",
    "        return X_padded.reshape(batch_size, 1, img_size, img_size)\n",
    "\n",
    "transformer = SimpleDeepInsightTransformer()\n",
    "X_train_img = transformer.transform(X_train)\n",
    "X_test_img = transformer.transform(X_test)\n",
    "\n",
    "# (3) PyTorch Dataset & Model\n",
    "class IVFDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y) if y is not None else None\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None: return self.X[idx], self.y[idx]\n",
    "        return self.X[idx]\n",
    "\n",
    "# ResNet18 ìˆ˜ì • ëª¨ë¸\n",
    "class DeepInsightResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet18(pretrained=False) # êµ¬ì¡°ë§Œ ì‚¬ìš©\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 1)\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.model(x))\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„ (ê°„ì†Œí™”)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DeepInsightResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()\n",
    "loader = DataLoader(IVFDataset(X_train_img, y_train), batch_size=64, shuffle=True)\n",
    "\n",
    "print(\"   âš™ï¸ CNN Training Epochs (ì•½ì‹ ì§„í–‰)...\")\n",
    "model.train()\n",
    "for epoch in range(3): # ì‹œê°„ ê´€ê³„ìƒ 3 Epochë§Œ (ì‹¤ì „ì—” 10+)\n",
    "    for X_batch, y_batch in loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# ì¶”ë¡ \n",
    "model.eval()\n",
    "test_loader = DataLoader(IVFDataset(X_test_img), batch_size=64)\n",
    "pred_deep_list = []\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        pred_deep_list.extend(model(X_batch.to(device)).cpu().numpy().flatten())\n",
    "\n",
    "pred_deep = np.array(pred_deep_list)\n",
    "print(\"   âœ… DeepInsight ì˜ˆì¸¡ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================\n",
    "# 6. [Final] Grand Fusion (ì•™ìƒë¸”)\n",
    "# ======================================================================================\n",
    "print(\"ğŸš€ [Final] ìµœì¢… ë¸”ë Œë”© ë° íŒŒì¼ ì €ì¥...\")\n",
    "\n",
    "# 1. Rank Breaker (50% Bitna + 50% Group6)\n",
    "# ìœ„ì—ì„œ ì´ë¯¸ ê³„ì‚°ë¨: prob_breaker\n",
    "\n",
    "# 2. Sniper / Blend 20 (ì¤‘ê°„ ì‚°ì¶œë¬¼ ì €ì¥ - ê²€ì¦ìš©)\n",
    "prob_blend_20 = (prob_breaker * 0.8) + (pred_hidden * 0.2)\n",
    "pd.DataFrame({'ID': test_origin['ID'], 'probability': prob_blend_20}).to_csv('submission_blend_20.csv', index=False)\n",
    "\n",
    "# 3. Final Fusion (Twin Engine Strategy)\n",
    "# ë¹„ìœ¨: Rank Breaker(70%) + Hidden(15%) + Deep(15%)\n",
    "w_breaker = 0.70\n",
    "w_hidden = 0.15\n",
    "w_deep = 0.15\n",
    "\n",
    "final_prob = (\n",
    "    (prob_breaker * w_breaker) + \n",
    "    (pred_hidden * w_hidden) + \n",
    "    (pred_deep * w_deep)\n",
    ")\n",
    "\n",
    "# ìµœì¢… íŒŒì¼ ì €ì¥\n",
    "final_submission = pd.DataFrame({\n",
    "    'ID': test_origin['ID'],\n",
    "    'probability': final_prob\n",
    "})\n",
    "\n",
    "filename = 'submission_fusion_1515.csv'\n",
    "final_submission.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\nğŸ† [Mission Complete] ìµœì¢… íŒŒì¼ ìƒì„± ì™„ë£Œ: {filename}\")\n",
    "print(f\"   ğŸ‘‰ ëª¨ë¸ êµ¬ì„±: AutoGluon(Stacking) + CNN(DeepInsight)\")\n",
    "print(f\"   ğŸ‘‰ ì•™ìƒë¸” ë¹„ìœ¨: Breaker({w_breaker}) : Hidden({w_hidden}) : Deep({w_deep})\")\n",
    "print(\"   ğŸš€ ì¡°êµë‹˜ í™•ì¸ìš©: ëª¨ë“  ì½”ë“œê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ íŒŒì¼ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
